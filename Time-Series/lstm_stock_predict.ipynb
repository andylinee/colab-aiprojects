{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lstm_stock_predict.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQk9qa6uhk1c"
      },
      "source": [
        "reference: https://medium.com/@daniel820710/%E5%88%A9%E7%94%A8keras%E5%BB%BA%E6%A7%8Blstm%E6%A8%A1%E5%9E%8B-%E4%BB%A5stock-prediction-%E7%82%BA%E4%BE%8B-1-67456e0a0b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QoL5Vl_-aJk"
      },
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "topgPtyi76Hq"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, LSTM, TimeDistributed, RepeatVector\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dv6FnXwf-jrx"
      },
      "source": [
        "# Define Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfZrXC1U-bkh"
      },
      "source": [
        "# Read Data\n",
        "# SPY dataset: Yahoo SPDR S&P 500 ETF (SPY):http://goo.gl/QXikaf\n",
        "def readTrain():\n",
        "  train = pd.read_csv(\"SPY.csv\")\n",
        "  return train\n",
        "\n",
        "# Augment Features\n",
        "def augFeatures(train):\n",
        "  train[\"Date\"] = pd.to_datetime(train[\"Date\"])\n",
        "  train[\"year\"] = train[\"Date\"].dt.year\n",
        "  train[\"month\"] = train[\"Date\"].dt.month\n",
        "  train[\"date\"] = train[\"Date\"].dt.day\n",
        "  train[\"day\"] = train[\"Date\"].dt.dayofweek\n",
        "  return train\n",
        "\n",
        "# Normalization\n",
        "def normalize(train):\n",
        "  train = train.drop([\"Date\"], axis=1)\n",
        "  train_norm = train.apply(lambda x: (x - np.mean(x)) / (np.max(x) - np.min(x)))\n",
        "  return train_norm\n",
        "\n",
        "# Build Train\n",
        "def buildTrain(train, pastDay=30, futureDay=5):\n",
        "  X_train, Y_train = [], []\n",
        "  for i in range(train.shape[0]-futureDay-pastDay):\n",
        "    X_train.append(np.array(train.iloc[i:i+pastDay]))\n",
        "    Y_train.append(np.array(train.iloc[i+pastDay:i+pastDay+futureDay][\"Adj Close\"]))\n",
        "  return np.array(X_train), np.array(Y_train)\n",
        "\n",
        "# Shuffle Data\n",
        "def shuffle(X,Y):\n",
        "  np.random.seed(10)\n",
        "  randomList = np.arange(X.shape[0])\n",
        "  np.random.shuffle(randomList)\n",
        "  return X[randomList], Y[randomList]\n",
        "\n",
        "# Train/Valid Split\n",
        "def splitData(X,Y,rate):\n",
        "  X_train = X[int(X.shape[0]*rate):]\n",
        "  Y_train = Y[int(Y.shape[0]*rate):]\n",
        "  X_val = X[:int(X.shape[0]*rate)]\n",
        "  Y_val = Y[:int(Y.shape[0]*rate)]\n",
        "  return X_train, Y_train, X_val, Y_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7FJReAR_eje"
      },
      "source": [
        "# Dataset Preparing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "LkSPvQEBNo33",
        "outputId": "fb728454-cab0-4cd9-8693-59076aaae56a"
      },
      "source": [
        "# read SPY.csv\n",
        "train = readTrain()\n",
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1993-01-29</td>\n",
              "      <td>43.96875</td>\n",
              "      <td>43.96875</td>\n",
              "      <td>43.75000</td>\n",
              "      <td>43.93750</td>\n",
              "      <td>25.968958</td>\n",
              "      <td>1003200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1993-02-01</td>\n",
              "      <td>43.96875</td>\n",
              "      <td>44.25000</td>\n",
              "      <td>43.96875</td>\n",
              "      <td>44.25000</td>\n",
              "      <td>26.153660</td>\n",
              "      <td>480500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1993-02-02</td>\n",
              "      <td>44.21875</td>\n",
              "      <td>44.37500</td>\n",
              "      <td>44.12500</td>\n",
              "      <td>44.34375</td>\n",
              "      <td>26.209057</td>\n",
              "      <td>201300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1993-02-03</td>\n",
              "      <td>44.40625</td>\n",
              "      <td>44.84375</td>\n",
              "      <td>44.37500</td>\n",
              "      <td>44.81250</td>\n",
              "      <td>26.486113</td>\n",
              "      <td>529400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1993-02-04</td>\n",
              "      <td>44.96875</td>\n",
              "      <td>45.09375</td>\n",
              "      <td>44.46875</td>\n",
              "      <td>45.00000</td>\n",
              "      <td>26.596937</td>\n",
              "      <td>531500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Date      Open      High       Low     Close  Adj Close   Volume\n",
              "0  1993-01-29  43.96875  43.96875  43.75000  43.93750  25.968958  1003200\n",
              "1  1993-02-01  43.96875  44.25000  43.96875  44.25000  26.153660   480500\n",
              "2  1993-02-02  44.21875  44.37500  44.12500  44.34375  26.209057   201300\n",
              "3  1993-02-03  44.40625  44.84375  44.37500  44.81250  26.486113   529400\n",
              "4  1993-02-04  44.96875  45.09375  44.46875  45.00000  26.596937   531500"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "-K_gezRmOMKM",
        "outputId": "ac480fe3-161d-4199-c02c-22e5516592ae"
      },
      "source": [
        "# Augment the features (year, month, date, day)\n",
        "train_Aug = augFeatures(train)\n",
        "train_Aug.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>date</th>\n",
              "      <th>day</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1993-01-29</td>\n",
              "      <td>43.96875</td>\n",
              "      <td>43.96875</td>\n",
              "      <td>43.75000</td>\n",
              "      <td>43.93750</td>\n",
              "      <td>25.968958</td>\n",
              "      <td>1003200</td>\n",
              "      <td>1993</td>\n",
              "      <td>1</td>\n",
              "      <td>29</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1993-02-01</td>\n",
              "      <td>43.96875</td>\n",
              "      <td>44.25000</td>\n",
              "      <td>43.96875</td>\n",
              "      <td>44.25000</td>\n",
              "      <td>26.153660</td>\n",
              "      <td>480500</td>\n",
              "      <td>1993</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1993-02-02</td>\n",
              "      <td>44.21875</td>\n",
              "      <td>44.37500</td>\n",
              "      <td>44.12500</td>\n",
              "      <td>44.34375</td>\n",
              "      <td>26.209057</td>\n",
              "      <td>201300</td>\n",
              "      <td>1993</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1993-02-03</td>\n",
              "      <td>44.40625</td>\n",
              "      <td>44.84375</td>\n",
              "      <td>44.37500</td>\n",
              "      <td>44.81250</td>\n",
              "      <td>26.486113</td>\n",
              "      <td>529400</td>\n",
              "      <td>1993</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1993-02-04</td>\n",
              "      <td>44.96875</td>\n",
              "      <td>45.09375</td>\n",
              "      <td>44.46875</td>\n",
              "      <td>45.00000</td>\n",
              "      <td>26.596937</td>\n",
              "      <td>531500</td>\n",
              "      <td>1993</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Date      Open      High       Low  ...  year  month  date  day\n",
              "0 1993-01-29  43.96875  43.96875  43.75000  ...  1993      1    29    4\n",
              "1 1993-02-01  43.96875  44.25000  43.96875  ...  1993      2     1    0\n",
              "2 1993-02-02  44.21875  44.37500  44.12500  ...  1993      2     2    1\n",
              "3 1993-02-03  44.40625  44.84375  44.37500  ...  1993      2     3    2\n",
              "4 1993-02-04  44.96875  45.09375  44.46875  ...  1993      2     4    3\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "3Z-dH8nyOP-e",
        "outputId": "229f5b8e-c21e-4621-c440-3ce4d4e66ee9"
      },
      "source": [
        "# Normalization\n",
        "train_norm = normalize(train_Aug)\n",
        "train_norm.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>date</th>\n",
              "      <th>day</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.342052</td>\n",
              "      <td>-0.344423</td>\n",
              "      <td>-0.340762</td>\n",
              "      <td>-0.341338</td>\n",
              "      <td>-0.301050</td>\n",
              "      <td>-0.095759</td>\n",
              "      <td>-0.486789</td>\n",
              "      <td>-0.501146</td>\n",
              "      <td>0.442720</td>\n",
              "      <td>0.494918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.342052</td>\n",
              "      <td>-0.343266</td>\n",
              "      <td>-0.339857</td>\n",
              "      <td>-0.340053</td>\n",
              "      <td>-0.300297</td>\n",
              "      <td>-0.096359</td>\n",
              "      <td>-0.486789</td>\n",
              "      <td>-0.410237</td>\n",
              "      <td>-0.490614</td>\n",
              "      <td>-0.505082</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.341021</td>\n",
              "      <td>-0.342752</td>\n",
              "      <td>-0.339210</td>\n",
              "      <td>-0.339668</td>\n",
              "      <td>-0.300072</td>\n",
              "      <td>-0.096680</td>\n",
              "      <td>-0.486789</td>\n",
              "      <td>-0.410237</td>\n",
              "      <td>-0.457280</td>\n",
              "      <td>-0.255082</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.340248</td>\n",
              "      <td>-0.340824</td>\n",
              "      <td>-0.338176</td>\n",
              "      <td>-0.337740</td>\n",
              "      <td>-0.298942</td>\n",
              "      <td>-0.096303</td>\n",
              "      <td>-0.486789</td>\n",
              "      <td>-0.410237</td>\n",
              "      <td>-0.423947</td>\n",
              "      <td>-0.005082</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.337930</td>\n",
              "      <td>-0.339796</td>\n",
              "      <td>-0.337788</td>\n",
              "      <td>-0.336969</td>\n",
              "      <td>-0.298490</td>\n",
              "      <td>-0.096301</td>\n",
              "      <td>-0.486789</td>\n",
              "      <td>-0.410237</td>\n",
              "      <td>-0.390614</td>\n",
              "      <td>0.244918</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Open      High       Low  ...     month      date       day\n",
              "0 -0.342052 -0.344423 -0.340762  ... -0.501146  0.442720  0.494918\n",
              "1 -0.342052 -0.343266 -0.339857  ... -0.410237 -0.490614 -0.505082\n",
              "2 -0.341021 -0.342752 -0.339210  ... -0.410237 -0.457280 -0.255082\n",
              "3 -0.340248 -0.340824 -0.338176  ... -0.410237 -0.423947 -0.005082\n",
              "4 -0.337930 -0.339796 -0.337788  ... -0.410237 -0.390614  0.244918\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZsOX0jQ_YXB"
      },
      "source": [
        "# build Data, use last 30 days to predict next 5 days\n",
        "X_train, Y_train = buildTrain(train_norm, 30, 5)\n",
        "\n",
        "# shuffle the data, and random seed is 10\n",
        "X_train, Y_train = shuffle(X_train, Y_train)\n",
        "\n",
        "# split training data and validation data\n",
        "X_train, Y_train, X_val, Y_val = splitData(X_train, Y_train, 0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5gAzbsb_goF",
        "outputId": "e6dffbf6-cfd5-4910-9fa3-22b156a24e49"
      },
      "source": [
        "print(\"X_train: \", X_train.shape)\n",
        "print(\"Y_train: \", Y_train.shape)\n",
        "print(\"X_val: \", X_val.shape)\n",
        "print(\"Y_val: \", Y_val.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train:  (5680, 30, 10)\n",
            "Y_train:  (5680, 5)\n",
            "X_val:  (631, 30, 10)\n",
            "Y_val:  (631, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "T1ATTsZsNNK2",
        "outputId": "48dbef73-f1d1-4a7f-defd-05d5f03ffcfa"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>date</th>\n",
              "      <th>day</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1993-01-29</td>\n",
              "      <td>43.96875</td>\n",
              "      <td>43.96875</td>\n",
              "      <td>43.75000</td>\n",
              "      <td>43.93750</td>\n",
              "      <td>25.968958</td>\n",
              "      <td>1003200</td>\n",
              "      <td>1993</td>\n",
              "      <td>1</td>\n",
              "      <td>29</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1993-02-01</td>\n",
              "      <td>43.96875</td>\n",
              "      <td>44.25000</td>\n",
              "      <td>43.96875</td>\n",
              "      <td>44.25000</td>\n",
              "      <td>26.153660</td>\n",
              "      <td>480500</td>\n",
              "      <td>1993</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1993-02-02</td>\n",
              "      <td>44.21875</td>\n",
              "      <td>44.37500</td>\n",
              "      <td>44.12500</td>\n",
              "      <td>44.34375</td>\n",
              "      <td>26.209057</td>\n",
              "      <td>201300</td>\n",
              "      <td>1993</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1993-02-03</td>\n",
              "      <td>44.40625</td>\n",
              "      <td>44.84375</td>\n",
              "      <td>44.37500</td>\n",
              "      <td>44.81250</td>\n",
              "      <td>26.486113</td>\n",
              "      <td>529400</td>\n",
              "      <td>1993</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1993-02-04</td>\n",
              "      <td>44.96875</td>\n",
              "      <td>45.09375</td>\n",
              "      <td>44.46875</td>\n",
              "      <td>45.00000</td>\n",
              "      <td>26.596937</td>\n",
              "      <td>531500</td>\n",
              "      <td>1993</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Date      Open      High       Low  ...  year  month  date  day\n",
              "0 1993-01-29  43.96875  43.96875  43.75000  ...  1993      1    29    4\n",
              "1 1993-02-01  43.96875  44.25000  43.96875  ...  1993      2     1    0\n",
              "2 1993-02-02  44.21875  44.37500  44.12500  ...  1993      2     2    1\n",
              "3 1993-02-03  44.40625  44.84375  44.37500  ...  1993      2     3    2\n",
              "4 1993-02-04  44.96875  45.09375  44.46875  ...  1993      2     4    3\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "GfUmEfheNEdL",
        "outputId": "e61a1dac-63bd-4cfa-f6da-9562dddb237b"
      },
      "source": [
        "train_Aug.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>date</th>\n",
              "      <th>day</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1993-01-29</td>\n",
              "      <td>43.96875</td>\n",
              "      <td>43.96875</td>\n",
              "      <td>43.75000</td>\n",
              "      <td>43.93750</td>\n",
              "      <td>25.968958</td>\n",
              "      <td>1003200</td>\n",
              "      <td>1993</td>\n",
              "      <td>1</td>\n",
              "      <td>29</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1993-02-01</td>\n",
              "      <td>43.96875</td>\n",
              "      <td>44.25000</td>\n",
              "      <td>43.96875</td>\n",
              "      <td>44.25000</td>\n",
              "      <td>26.153660</td>\n",
              "      <td>480500</td>\n",
              "      <td>1993</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1993-02-02</td>\n",
              "      <td>44.21875</td>\n",
              "      <td>44.37500</td>\n",
              "      <td>44.12500</td>\n",
              "      <td>44.34375</td>\n",
              "      <td>26.209057</td>\n",
              "      <td>201300</td>\n",
              "      <td>1993</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1993-02-03</td>\n",
              "      <td>44.40625</td>\n",
              "      <td>44.84375</td>\n",
              "      <td>44.37500</td>\n",
              "      <td>44.81250</td>\n",
              "      <td>26.486113</td>\n",
              "      <td>529400</td>\n",
              "      <td>1993</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1993-02-04</td>\n",
              "      <td>44.96875</td>\n",
              "      <td>45.09375</td>\n",
              "      <td>44.46875</td>\n",
              "      <td>45.00000</td>\n",
              "      <td>26.596937</td>\n",
              "      <td>531500</td>\n",
              "      <td>1993</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Date      Open      High       Low  ...  year  month  date  day\n",
              "0 1993-01-29  43.96875  43.96875  43.75000  ...  1993      1    29    4\n",
              "1 1993-02-01  43.96875  44.25000  43.96875  ...  1993      2     1    0\n",
              "2 1993-02-02  44.21875  44.37500  44.12500  ...  1993      2     2    1\n",
              "3 1993-02-03  44.40625  44.84375  44.37500  ...  1993      2     3    2\n",
              "4 1993-02-04  44.96875  45.09375  44.46875  ...  1993      2     4    3\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeBip7870g3U"
      },
      "source": [
        "# Many-to-One Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKUb1-lD0jtI"
      },
      "source": [
        "def buildManyToOneModel(shape):\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(10, input_length=shape[1], input_dim=shape[2]))\n",
        "  # output shape: (1, 1)\n",
        "  model.add(Dense(1))\n",
        "  model.compile(loss=\"mse\", optimizer=\"adam\")\n",
        "  model.summary()\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1eMNUmf-0mqo",
        "outputId": "688f0c0b-f462-4df4-f37d-140d8237248b"
      },
      "source": [
        "train = readTrain()\n",
        "train_Aug = augFeatures(train)\n",
        "train_norm = normalize(train_Aug)\n",
        "# change the last day and next day \n",
        "X_train, Y_train = buildTrain(train_norm, 30, 1)\n",
        "X_train, Y_train = shuffle(X_train, Y_train)\n",
        "# because no return sequence, Y_train and Y_val shape must be 2 dimension\n",
        "X_train, Y_train, X_val, Y_val = splitData(X_train, Y_train, 0.1)\n",
        "\n",
        "model = buildManyToOneModel(X_train.shape)\n",
        "callback = EarlyStopping(monitor=\"loss\", patience=10, verbose=1, mode=\"auto\")\n",
        "model.fit(X_train, Y_train, epochs=1000, batch_size=128, validation_data=(X_val, Y_val), callbacks=[callback])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 10)                840       \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 851\n",
            "Trainable params: 851\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/1000\n",
            "45/45 [==============================] - 8s 13ms/step - loss: 0.0175 - val_loss: 0.0020\n",
            "Epoch 2/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 7.8499e-04\n",
            "Epoch 3/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 7.0939e-04 - val_loss: 4.4657e-04\n",
            "Epoch 4/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 4.3224e-04 - val_loss: 3.0514e-04\n",
            "Epoch 5/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 3.0726e-04 - val_loss: 2.3986e-04\n",
            "Epoch 6/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 2.2875e-04 - val_loss: 2.0323e-04\n",
            "Epoch 7/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 1.8966e-04 - val_loss: 1.7702e-04\n",
            "Epoch 8/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 1.6512e-04 - val_loss: 1.5686e-04\n",
            "Epoch 9/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 1.4625e-04 - val_loss: 1.4192e-04\n",
            "Epoch 10/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 1.2835e-04 - val_loss: 1.3018e-04\n",
            "Epoch 11/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 1.2016e-04 - val_loss: 1.1947e-04\n",
            "Epoch 12/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 1.0752e-04 - val_loss: 1.1265e-04\n",
            "Epoch 13/1000\n",
            "45/45 [==============================] - 0s 7ms/step - loss: 1.0292e-04 - val_loss: 1.0407e-04\n",
            "Epoch 14/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 9.4700e-05 - val_loss: 9.8793e-05\n",
            "Epoch 15/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 8.6106e-05 - val_loss: 9.8828e-05\n",
            "Epoch 16/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 8.5317e-05 - val_loss: 8.7657e-05\n",
            "Epoch 17/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 8.3535e-05 - val_loss: 8.4535e-05\n",
            "Epoch 18/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 7.7128e-05 - val_loss: 8.2053e-05\n",
            "Epoch 19/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 7.5975e-05 - val_loss: 8.0562e-05\n",
            "Epoch 20/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 7.1423e-05 - val_loss: 7.4949e-05\n",
            "Epoch 21/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 6.8582e-05 - val_loss: 7.4348e-05\n",
            "Epoch 22/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 6.3399e-05 - val_loss: 7.0815e-05\n",
            "Epoch 23/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 6.3586e-05 - val_loss: 7.3872e-05\n",
            "Epoch 24/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 6.0747e-05 - val_loss: 7.2361e-05\n",
            "Epoch 25/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 6.5149e-05 - val_loss: 6.4457e-05\n",
            "Epoch 26/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 5.9384e-05 - val_loss: 6.5230e-05\n",
            "Epoch 27/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 6.1744e-05 - val_loss: 6.3474e-05\n",
            "Epoch 28/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 5.7184e-05 - val_loss: 6.1972e-05\n",
            "Epoch 29/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 5.6076e-05 - val_loss: 6.1471e-05\n",
            "Epoch 30/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 5.9222e-05 - val_loss: 5.8580e-05\n",
            "Epoch 31/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 5.5333e-05 - val_loss: 5.7564e-05\n",
            "Epoch 32/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 5.3072e-05 - val_loss: 5.7682e-05\n",
            "Epoch 33/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 5.2720e-05 - val_loss: 5.8539e-05\n",
            "Epoch 34/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 5.2757e-05 - val_loss: 5.5133e-05\n",
            "Epoch 35/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 5.3492e-05 - val_loss: 5.3412e-05\n",
            "Epoch 36/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 5.0323e-05 - val_loss: 5.4115e-05\n",
            "Epoch 37/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 4.9304e-05 - val_loss: 5.4044e-05\n",
            "Epoch 38/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 4.6999e-05 - val_loss: 5.3123e-05\n",
            "Epoch 39/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 4.9968e-05 - val_loss: 5.0993e-05\n",
            "Epoch 40/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 4.7421e-05 - val_loss: 5.0156e-05\n",
            "Epoch 41/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 4.6570e-05 - val_loss: 4.9421e-05\n",
            "Epoch 42/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 4.4614e-05 - val_loss: 4.9811e-05\n",
            "Epoch 43/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 4.4396e-05 - val_loss: 5.0939e-05\n",
            "Epoch 44/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 4.6495e-05 - val_loss: 4.8170e-05\n",
            "Epoch 45/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 4.1406e-05 - val_loss: 4.8456e-05\n",
            "Epoch 46/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 4.4032e-05 - val_loss: 4.8351e-05\n",
            "Epoch 47/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 4.5261e-05 - val_loss: 4.6149e-05\n",
            "Epoch 48/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 4.3279e-05 - val_loss: 4.8565e-05\n",
            "Epoch 49/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 4.5030e-05 - val_loss: 4.9318e-05\n",
            "Epoch 50/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 4.2583e-05 - val_loss: 4.8090e-05\n",
            "Epoch 51/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 4.0447e-05 - val_loss: 4.4536e-05\n",
            "Epoch 52/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 4.0828e-05 - val_loss: 4.3856e-05\n",
            "Epoch 53/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 3.9980e-05 - val_loss: 4.4395e-05\n",
            "Epoch 54/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 4.1931e-05 - val_loss: 4.4240e-05\n",
            "Epoch 55/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 4.1306e-05 - val_loss: 4.5171e-05\n",
            "Epoch 56/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 3.9225e-05 - val_loss: 4.6340e-05\n",
            "Epoch 57/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 4.0880e-05 - val_loss: 4.4776e-05\n",
            "Epoch 58/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 3.9297e-05 - val_loss: 4.8300e-05\n",
            "Epoch 59/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 4.1251e-05 - val_loss: 4.2369e-05\n",
            "Epoch 60/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 3.6169e-05 - val_loss: 4.2535e-05\n",
            "Epoch 61/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 3.9310e-05 - val_loss: 4.2139e-05\n",
            "Epoch 62/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 3.8276e-05 - val_loss: 4.4407e-05\n",
            "Epoch 63/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 3.7927e-05 - val_loss: 4.3550e-05\n",
            "Epoch 64/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 4.0059e-05 - val_loss: 4.1245e-05\n",
            "Epoch 65/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 3.8723e-05 - val_loss: 4.0385e-05\n",
            "Epoch 66/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 3.8161e-05 - val_loss: 3.9330e-05\n",
            "Epoch 67/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 3.5741e-05 - val_loss: 3.9939e-05\n",
            "Epoch 68/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 3.5963e-05 - val_loss: 3.9645e-05\n",
            "Epoch 69/1000\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 3.6459e-05 - val_loss: 4.0135e-05\n",
            "Epoch 70/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 3.4618e-05 - val_loss: 3.8408e-05\n",
            "Epoch 71/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 3.5797e-05 - val_loss: 3.8166e-05\n",
            "Epoch 72/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 3.7278e-05 - val_loss: 3.8560e-05\n",
            "Epoch 73/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 3.2403e-05 - val_loss: 4.2075e-05\n",
            "Epoch 74/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 3.7306e-05 - val_loss: 4.0887e-05\n",
            "Epoch 75/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 3.4649e-05 - val_loss: 3.8766e-05\n",
            "Epoch 76/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 3.3951e-05 - val_loss: 3.8845e-05\n",
            "Epoch 77/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 3.4310e-05 - val_loss: 3.9104e-05\n",
            "Epoch 78/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 3.4921e-05 - val_loss: 3.7618e-05\n",
            "Epoch 79/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 3.4500e-05 - val_loss: 3.6390e-05\n",
            "Epoch 80/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 3.1389e-05 - val_loss: 4.1603e-05\n",
            "Epoch 81/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 3.3930e-05 - val_loss: 3.6874e-05\n",
            "Epoch 82/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 3.1107e-05 - val_loss: 3.5053e-05\n",
            "Epoch 83/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 3.1767e-05 - val_loss: 3.7798e-05\n",
            "Epoch 84/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 3.3688e-05 - val_loss: 3.5496e-05\n",
            "Epoch 85/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 3.2707e-05 - val_loss: 3.5549e-05\n",
            "Epoch 86/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 3.0847e-05 - val_loss: 3.7040e-05\n",
            "Epoch 87/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 3.2994e-05 - val_loss: 4.6946e-05\n",
            "Epoch 88/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 3.4302e-05 - val_loss: 3.8654e-05\n",
            "Epoch 89/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 3.2597e-05 - val_loss: 3.4336e-05\n",
            "Epoch 90/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 2.9875e-05 - val_loss: 4.5373e-05\n",
            "Epoch 91/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 3.4045e-05 - val_loss: 3.8035e-05\n",
            "Epoch 92/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 3.1826e-05 - val_loss: 3.4454e-05\n",
            "Epoch 93/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 3.3261e-05 - val_loss: 3.6418e-05\n",
            "Epoch 94/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 3.0571e-05 - val_loss: 4.0368e-05\n",
            "Epoch 95/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 3.1468e-05 - val_loss: 3.4914e-05\n",
            "Epoch 96/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 3.1289e-05 - val_loss: 3.4545e-05\n",
            "Epoch 97/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 2.8376e-05 - val_loss: 3.4810e-05\n",
            "Epoch 98/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 3.0704e-05 - val_loss: 3.3162e-05\n",
            "Epoch 99/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 3.1214e-05 - val_loss: 3.8763e-05\n",
            "Epoch 100/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 2.9962e-05 - val_loss: 3.2646e-05\n",
            "Epoch 101/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 3.1386e-05 - val_loss: 3.3630e-05\n",
            "Epoch 102/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 3.1971e-05 - val_loss: 3.3943e-05\n",
            "Epoch 103/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 2.9916e-05 - val_loss: 3.2550e-05\n",
            "Epoch 104/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 2.8404e-05 - val_loss: 3.4177e-05\n",
            "Epoch 105/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 2.9229e-05 - val_loss: 3.2152e-05\n",
            "Epoch 106/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 3.0348e-05 - val_loss: 3.4891e-05\n",
            "Epoch 107/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 2.8940e-05 - val_loss: 3.1011e-05\n",
            "Epoch 108/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 2.8398e-05 - val_loss: 3.1209e-05\n",
            "Epoch 109/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 2.9718e-05 - val_loss: 3.1138e-05\n",
            "Epoch 110/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 2.8483e-05 - val_loss: 3.1174e-05\n",
            "Epoch 111/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 2.7088e-05 - val_loss: 3.0331e-05\n",
            "Epoch 112/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 3.0032e-05 - val_loss: 3.4172e-05\n",
            "Epoch 113/1000\n",
            "45/45 [==============================] - 0s 7ms/step - loss: 2.7223e-05 - val_loss: 3.1536e-05\n",
            "Epoch 114/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 2.7312e-05 - val_loss: 3.2070e-05\n",
            "Epoch 115/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 2.8240e-05 - val_loss: 3.1374e-05\n",
            "Epoch 116/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 2.9893e-05 - val_loss: 3.0336e-05\n",
            "Epoch 117/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 3.0319e-05 - val_loss: 3.0550e-05\n",
            "Epoch 118/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 2.7946e-05 - val_loss: 3.0519e-05\n",
            "Epoch 119/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 2.6649e-05 - val_loss: 3.3068e-05\n",
            "Epoch 120/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 3.0604e-05 - val_loss: 3.1151e-05\n",
            "Epoch 121/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 2.9403e-05 - val_loss: 2.9513e-05\n",
            "Epoch 122/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 2.7959e-05 - val_loss: 3.8462e-05\n",
            "Epoch 123/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 2.9640e-05 - val_loss: 4.1242e-05\n",
            "Epoch 124/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 3.0375e-05 - val_loss: 2.9733e-05\n",
            "Epoch 125/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 2.8570e-05 - val_loss: 3.2801e-05\n",
            "Epoch 126/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 2.7288e-05 - val_loss: 3.0411e-05\n",
            "Epoch 127/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 2.5510e-05 - val_loss: 2.9549e-05\n",
            "Epoch 128/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 2.7623e-05 - val_loss: 3.0125e-05\n",
            "Epoch 129/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 2.8401e-05 - val_loss: 3.1069e-05\n",
            "Epoch 130/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 2.6962e-05 - val_loss: 3.0986e-05\n",
            "Epoch 131/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 2.6417e-05 - val_loss: 3.7774e-05\n",
            "Epoch 132/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 2.7129e-05 - val_loss: 2.9009e-05\n",
            "Epoch 133/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 2.5676e-05 - val_loss: 2.8606e-05\n",
            "Epoch 134/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 2.8122e-05 - val_loss: 3.5234e-05\n",
            "Epoch 135/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 2.6427e-05 - val_loss: 2.9474e-05\n",
            "Epoch 136/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 3.2078e-05 - val_loss: 2.9325e-05\n",
            "Epoch 137/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 2.5868e-05 - val_loss: 3.1124e-05\n",
            "Epoch 138/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 2.7065e-05 - val_loss: 3.8925e-05\n",
            "Epoch 139/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 2.7672e-05 - val_loss: 3.2987e-05\n",
            "Epoch 140/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 2.9373e-05 - val_loss: 2.7666e-05\n",
            "Epoch 141/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 2.3665e-05 - val_loss: 3.8473e-05\n",
            "Epoch 142/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 2.9739e-05 - val_loss: 3.0204e-05\n",
            "Epoch 143/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 3.1315e-05 - val_loss: 2.7737e-05\n",
            "Epoch 00143: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb840089470>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhD5vBTG1ZtJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-Oiobsrg8MO"
      },
      "source": [
        "# Many-to-Many Model (5-5)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ih3KQRE_zvP"
      },
      "source": [
        "def buildManyToManyModel(shape):\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(10, input_length=shape[1], input_dim=shape[2], return_sequences=True))\n",
        "  # output shape: (5, 1)\n",
        "  model.add(TimeDistributed(Dense(1)))\n",
        "  model.compile(loss=\"mse\", optimizer=\"adam\")\n",
        "  model.summary()\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8kyc7ALg7W4",
        "outputId": "56491e10-7d15-41f7-f80f-e394a95d1686"
      },
      "source": [
        "train = readTrain()\n",
        "train_Aug = augFeatures(train)\n",
        "train_norm = normalize(train_Aug)\n",
        "# change the last day and next day \n",
        "X_train, Y_train = buildTrain(train_norm, 5, 5)\n",
        "X_train, Y_train = shuffle(X_train, Y_train)\n",
        "X_train, Y_train, X_val, Y_val = splitData(X_train, Y_train, 0.1)\n",
        "\n",
        "# from 2 dimmension to 3 dimension\n",
        "Y_train = Y_train[:,:,np.newaxis]\n",
        "Y_val = Y_val[:,:,np.newaxis]\n",
        "\n",
        "model = buildManyToManyModel(X_train.shape)\n",
        "callback = EarlyStopping(monitor=\"loss\", patience=10, verbose=1, mode=\"auto\")\n",
        "model.fit(X_train, Y_train, epochs=1000, batch_size=128, validation_data=(X_val, Y_val), callbacks=[callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 5, 10)             840       \n",
            "_________________________________________________________________\n",
            "time_distributed (TimeDistri (None, 5, 1)              11        \n",
            "=================================================================\n",
            "Total params: 851\n",
            "Trainable params: 851\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/1000\n",
            "45/45 [==============================] - 7s 11ms/step - loss: 0.0392 - val_loss: 0.0106\n",
            "Epoch 2/1000\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.0098 - val_loss: 0.0073\n",
            "Epoch 3/1000\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.0072 - val_loss: 0.0056\n",
            "Epoch 4/1000\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.0056 - val_loss: 0.0044\n",
            "Epoch 5/1000\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.0045 - val_loss: 0.0034\n",
            "Epoch 6/1000\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.0034 - val_loss: 0.0026\n",
            "Epoch 7/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0027 - val_loss: 0.0019\n",
            "Epoch 8/1000\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.0019 - val_loss: 0.0014\n",
            "Epoch 9/1000\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.0014 - val_loss: 0.0011\n",
            "Epoch 10/1000\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 0.0010 - val_loss: 8.3042e-04\n",
            "Epoch 11/1000\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 8.2425e-04 - val_loss: 6.7339e-04\n",
            "Epoch 12/1000\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 6.5563e-04 - val_loss: 5.6686e-04\n",
            "Epoch 13/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 5.3714e-04 - val_loss: 4.9087e-04\n",
            "Epoch 14/1000\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 4.7132e-04 - val_loss: 4.3270e-04\n",
            "Epoch 15/1000\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 4.1075e-04 - val_loss: 3.8942e-04\n",
            "Epoch 16/1000\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 3.6265e-04 - val_loss: 3.5306e-04\n",
            "Epoch 17/1000\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 3.3617e-04 - val_loss: 3.2523e-04\n",
            "Epoch 18/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 3.0456e-04 - val_loss: 3.0257e-04\n",
            "Epoch 19/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 2.8334e-04 - val_loss: 2.8404e-04\n",
            "Epoch 20/1000\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 2.6841e-04 - val_loss: 2.6826e-04\n",
            "Epoch 21/1000\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 2.5979e-04 - val_loss: 2.5390e-04\n",
            "Epoch 22/1000\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 2.4123e-04 - val_loss: 2.4299e-04\n",
            "Epoch 23/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 2.2988e-04 - val_loss: 2.3201e-04\n",
            "Epoch 24/1000\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 2.1704e-04 - val_loss: 2.2155e-04\n",
            "Epoch 25/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 2.0713e-04 - val_loss: 2.1175e-04\n",
            "Epoch 26/1000\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 1.9848e-04 - val_loss: 2.0375e-04\n",
            "Epoch 27/1000\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 1.9207e-04 - val_loss: 1.9422e-04\n",
            "Epoch 28/1000\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 1.8428e-04 - val_loss: 1.8709e-04\n",
            "Epoch 29/1000\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 1.7548e-04 - val_loss: 1.7923e-04\n",
            "Epoch 30/1000\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 1.7140e-04 - val_loss: 1.7400e-04\n",
            "Epoch 31/1000\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 1.6372e-04 - val_loss: 1.6652e-04\n",
            "Epoch 32/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 1.6063e-04 - val_loss: 1.6306e-04\n",
            "Epoch 33/1000\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 1.5245e-04 - val_loss: 1.5679e-04\n",
            "Epoch 34/1000\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 1.5172e-04 - val_loss: 1.5170e-04\n",
            "Epoch 35/1000\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 1.4591e-04 - val_loss: 1.4639e-04\n",
            "Epoch 36/1000\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 1.4183e-04 - val_loss: 1.4202e-04\n",
            "Epoch 37/1000\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 1.3325e-04 - val_loss: 1.3812e-04\n",
            "Epoch 38/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 1.3550e-04 - val_loss: 1.3487e-04\n",
            "Epoch 39/1000\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 1.3122e-04 - val_loss: 1.3159e-04\n",
            "Epoch 40/1000\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 1.2005e-04 - val_loss: 1.2869e-04\n",
            "Epoch 41/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 1.2713e-04 - val_loss: 1.2555e-04\n",
            "Epoch 42/1000\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 1.2040e-04 - val_loss: 1.2333e-04\n",
            "Epoch 43/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 1.1523e-04 - val_loss: 1.2159e-04\n",
            "Epoch 44/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 1.1693e-04 - val_loss: 1.2002e-04\n",
            "Epoch 45/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 1.1179e-04 - val_loss: 1.1760e-04\n",
            "Epoch 46/1000\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 1.1644e-04 - val_loss: 1.1663e-04\n",
            "Epoch 47/1000\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 1.1008e-04 - val_loss: 1.1495e-04\n",
            "Epoch 48/1000\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 1.1159e-04 - val_loss: 1.1351e-04\n",
            "Epoch 49/1000\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 1.1023e-04 - val_loss: 1.1248e-04\n",
            "Epoch 50/1000\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 1.1023e-04 - val_loss: 1.1157e-04\n",
            "Epoch 51/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 1.0992e-04 - val_loss: 1.1118e-04\n",
            "Epoch 52/1000\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 1.1123e-04 - val_loss: 1.1121e-04\n",
            "Epoch 53/1000\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 1.0499e-04 - val_loss: 1.1143e-04\n",
            "Epoch 54/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 9.9420e-05 - val_loss: 1.1006e-04\n",
            "Epoch 55/1000\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 1.0778e-04 - val_loss: 1.1062e-04\n",
            "Epoch 56/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 1.0612e-04 - val_loss: 1.0948e-04\n",
            "Epoch 57/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 1.0666e-04 - val_loss: 1.0761e-04\n",
            "Epoch 58/1000\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 1.0326e-04 - val_loss: 1.0762e-04\n",
            "Epoch 59/1000\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 1.0507e-04 - val_loss: 1.0908e-04\n",
            "Epoch 60/1000\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 1.0933e-04 - val_loss: 1.0809e-04\n",
            "Epoch 61/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 1.0527e-04 - val_loss: 1.0688e-04\n",
            "Epoch 62/1000\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 1.0304e-04 - val_loss: 1.0709e-04\n",
            "Epoch 63/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 1.0194e-04 - val_loss: 1.0601e-04\n",
            "Epoch 64/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 9.8673e-05 - val_loss: 1.0536e-04\n",
            "Epoch 65/1000\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 9.8060e-05 - val_loss: 1.0762e-04\n",
            "Epoch 66/1000\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 1.0209e-04 - val_loss: 1.0514e-04\n",
            "Epoch 67/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 1.0003e-04 - val_loss: 1.0662e-04\n",
            "Epoch 68/1000\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 1.0119e-04 - val_loss: 1.0640e-04\n",
            "Epoch 69/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 1.0082e-04 - val_loss: 1.0381e-04\n",
            "Epoch 70/1000\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 1.0112e-04 - val_loss: 1.0499e-04\n",
            "Epoch 71/1000\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 1.0164e-04 - val_loss: 1.0373e-04\n",
            "Epoch 72/1000\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 9.5735e-05 - val_loss: 1.0396e-04\n",
            "Epoch 73/1000\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 1.0127e-04 - val_loss: 1.0382e-04\n",
            "Epoch 74/1000\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 9.8552e-05 - val_loss: 1.0305e-04\n",
            "Epoch 75/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 1.0125e-04 - val_loss: 1.0408e-04\n",
            "Epoch 76/1000\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 9.8416e-05 - val_loss: 1.0353e-04\n",
            "Epoch 77/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 9.7829e-05 - val_loss: 1.0234e-04\n",
            "Epoch 78/1000\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 9.9872e-05 - val_loss: 1.0416e-04\n",
            "Epoch 79/1000\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 9.5901e-05 - val_loss: 1.0229e-04\n",
            "Epoch 80/1000\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 1.0092e-04 - val_loss: 1.0385e-04\n",
            "Epoch 81/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 1.0206e-04 - val_loss: 1.0464e-04\n",
            "Epoch 82/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 9.7147e-05 - val_loss: 1.0222e-04\n",
            "Epoch 83/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 9.5964e-05 - val_loss: 1.0174e-04\n",
            "Epoch 84/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 9.6922e-05 - val_loss: 1.0159e-04\n",
            "Epoch 85/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 9.9836e-05 - val_loss: 1.0102e-04\n",
            "Epoch 86/1000\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 9.6419e-05 - val_loss: 1.0128e-04\n",
            "Epoch 87/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 9.4924e-05 - val_loss: 1.0014e-04\n",
            "Epoch 88/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 9.5007e-05 - val_loss: 1.0198e-04\n",
            "Epoch 89/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 9.5371e-05 - val_loss: 1.0282e-04\n",
            "Epoch 90/1000\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 9.8353e-05 - val_loss: 1.0622e-04\n",
            "Epoch 91/1000\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 1.0228e-04 - val_loss: 1.0046e-04\n",
            "Epoch 92/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 9.6854e-05 - val_loss: 1.0143e-04\n",
            "Epoch 93/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 9.3870e-05 - val_loss: 1.0094e-04\n",
            "Epoch 94/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 9.3631e-05 - val_loss: 1.0115e-04\n",
            "Epoch 95/1000\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 9.4641e-05 - val_loss: 1.0093e-04\n",
            "Epoch 96/1000\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 9.8486e-05 - val_loss: 9.9770e-05\n",
            "Epoch 97/1000\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 9.8414e-05 - val_loss: 1.0036e-04\n",
            "Epoch 98/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 8.7827e-05 - val_loss: 9.9341e-05\n",
            "Epoch 99/1000\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 9.4614e-05 - val_loss: 1.0211e-04\n",
            "Epoch 100/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 9.9616e-05 - val_loss: 1.0335e-04\n",
            "Epoch 101/1000\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 9.0671e-05 - val_loss: 1.0074e-04\n",
            "Epoch 102/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 9.3541e-05 - val_loss: 1.0353e-04\n",
            "Epoch 103/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 9.6925e-05 - val_loss: 1.0076e-04\n",
            "Epoch 104/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 9.9486e-05 - val_loss: 9.9030e-05\n",
            "Epoch 105/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 9.6468e-05 - val_loss: 9.7905e-05\n",
            "Epoch 106/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 9.4865e-05 - val_loss: 9.9808e-05\n",
            "Epoch 107/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 9.0853e-05 - val_loss: 9.7995e-05\n",
            "Epoch 108/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 9.8093e-05 - val_loss: 9.8122e-05\n",
            "Epoch 109/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 9.2500e-05 - val_loss: 9.7724e-05\n",
            "Epoch 110/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 9.4514e-05 - val_loss: 9.7741e-05\n",
            "Epoch 111/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 9.1133e-05 - val_loss: 9.7157e-05\n",
            "Epoch 112/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 9.1526e-05 - val_loss: 9.9456e-05\n",
            "Epoch 113/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 9.4544e-05 - val_loss: 9.8133e-05\n",
            "Epoch 114/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 9.4382e-05 - val_loss: 9.7396e-05\n",
            "Epoch 115/1000\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 9.2316e-05 - val_loss: 9.7527e-05\n",
            "Epoch 116/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 8.9506e-05 - val_loss: 9.7405e-05\n",
            "Epoch 117/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 9.1203e-05 - val_loss: 9.7286e-05\n",
            "Epoch 118/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 8.9347e-05 - val_loss: 9.7430e-05\n",
            "Epoch 119/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 9.1363e-05 - val_loss: 9.6562e-05\n",
            "Epoch 120/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 9.5330e-05 - val_loss: 1.0041e-04\n",
            "Epoch 121/1000\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 9.4757e-05 - val_loss: 9.8644e-05\n",
            "Epoch 122/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 9.4337e-05 - val_loss: 9.6987e-05\n",
            "Epoch 123/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 9.2213e-05 - val_loss: 9.8940e-05\n",
            "Epoch 124/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 9.0876e-05 - val_loss: 9.7491e-05\n",
            "Epoch 125/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 9.2554e-05 - val_loss: 9.7124e-05\n",
            "Epoch 126/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 9.4117e-05 - val_loss: 9.7351e-05\n",
            "Epoch 127/1000\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 9.1762e-05 - val_loss: 9.6973e-05\n",
            "Epoch 128/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 9.0560e-05 - val_loss: 9.6027e-05\n",
            "Epoch 129/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 8.6965e-05 - val_loss: 9.7155e-05\n",
            "Epoch 130/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 9.0719e-05 - val_loss: 9.7095e-05\n",
            "Epoch 131/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 9.5960e-05 - val_loss: 9.7064e-05\n",
            "Epoch 132/1000\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 9.4920e-05 - val_loss: 9.6759e-05\n",
            "Epoch 133/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 9.0076e-05 - val_loss: 1.0140e-04\n",
            "Epoch 134/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 9.3276e-05 - val_loss: 1.0131e-04\n",
            "Epoch 135/1000\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 9.4173e-05 - val_loss: 9.7152e-05\n",
            "Epoch 136/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 9.0342e-05 - val_loss: 9.5721e-05\n",
            "Epoch 137/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 9.0179e-05 - val_loss: 9.5720e-05\n",
            "Epoch 138/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 9.2072e-05 - val_loss: 9.6392e-05\n",
            "Epoch 139/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 9.1420e-05 - val_loss: 9.5688e-05\n",
            "Epoch 140/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 9.2145e-05 - val_loss: 9.7261e-05\n",
            "Epoch 141/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 9.0292e-05 - val_loss: 9.7019e-05\n",
            "Epoch 142/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 9.4999e-05 - val_loss: 1.0361e-04\n",
            "Epoch 143/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 9.1827e-05 - val_loss: 9.6359e-05\n",
            "Epoch 144/1000\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 9.0345e-05 - val_loss: 9.8836e-05\n",
            "Epoch 145/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 9.1510e-05 - val_loss: 9.5600e-05\n",
            "Epoch 146/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 8.4755e-05 - val_loss: 9.6079e-05\n",
            "Epoch 147/1000\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 9.0696e-05 - val_loss: 9.7585e-05\n",
            "Epoch 148/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 8.8202e-05 - val_loss: 9.4683e-05\n",
            "Epoch 149/1000\n",
            "45/45 [==============================] - 0s 3ms/step - loss: 9.1358e-05 - val_loss: 9.5392e-05\n",
            "Epoch 150/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 9.1683e-05 - val_loss: 9.4898e-05\n",
            "Epoch 151/1000\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 9.0968e-05 - val_loss: 9.4844e-05\n",
            "Epoch 00151: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd2f0078438>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_u_exxx6hD0-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23YEuh-2Pn14"
      },
      "source": [
        "# Many-to-Many(30-5)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1Kgo0VcPqVH"
      },
      "source": [
        "def buildManyToManyModel(shape):\n",
        "  model = Sequential()  \n",
        "  model.add(LSTM(32, input_shape=(shape[1], shape[2]), return_sequences=False))  \n",
        "  model.add(RepeatVector(5)) \n",
        "  model.add(LSTM(32, return_sequences=True))  \n",
        "  model.add(TimeDistributed(Dense(1))) \n",
        "  model.compile(loss=\"mse\", optimizer=\"adam\")\n",
        "  model.summary()\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teFp0imdQLKP"
      },
      "source": [
        "train = readTrain()\n",
        "train_Aug = augFeatures(train)\n",
        "train_norm = normalize(train_Aug)\n",
        "# change the last day and next day \n",
        "X_train, Y_train = buildTrain(train_norm, 30, 5)\n",
        "X_train, Y_train = shuffle(X_train, Y_train)\n",
        "X_train, Y_train, X_val, Y_val = splitData(X_train, Y_train, 0.1)\n",
        "\n",
        "# from 2 dimmension to 3 dimension\n",
        "Y_train = Y_train[:,:,np.newaxis]\n",
        "Y_val = Y_val[:,:,np.newaxis]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXPOQ1UxRY_7",
        "outputId": "4fbd70c2-2971-4845-d49d-c20b58a39e01"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5680, 30, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSMvgqofWHxh",
        "outputId": "49a53914-22ac-4888-8b2e-9f9ea7e0ae62"
      },
      "source": [
        "Y_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5680, 5, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zkx67APUQV1E",
        "outputId": "64736f2b-71ed-4f3e-929f-79759dda3f75"
      },
      "source": [
        "model = buildManyToManyModel(X_train.shape)\n",
        "callback = EarlyStopping(monitor=\"loss\", patience=10, verbose=1, mode=\"auto\")\n",
        "model.fit(X_train, Y_train, epochs=1000, batch_size=128, validation_data=(X_val, Y_val), callbacks=[callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 32)                5504      \n",
            "_________________________________________________________________\n",
            "repeat_vector (RepeatVector) (None, 5, 32)             0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 5, 32)             8320      \n",
            "_________________________________________________________________\n",
            "time_distributed (TimeDistri (None, 5, 1)              33        \n",
            "=================================================================\n",
            "Total params: 13,857\n",
            "Trainable params: 13,857\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/1000\n",
            "45/45 [==============================] - 34s 24ms/step - loss: 0.0167 - val_loss: 0.0031\n",
            "Epoch 2/1000\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 0.0022 - val_loss: 8.3221e-04\n",
            "Epoch 3/1000\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 7.2994e-04 - val_loss: 4.6466e-04\n",
            "Epoch 4/1000\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 3.9616e-04 - val_loss: 2.9640e-04\n",
            "Epoch 5/1000\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 2.7318e-04 - val_loss: 2.1252e-04\n",
            "Epoch 6/1000\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 1.9296e-04 - val_loss: 1.4154e-04\n",
            "Epoch 7/1000\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 1.3599e-04 - val_loss: 1.0470e-04\n",
            "Epoch 8/1000\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 9.8540e-05 - val_loss: 9.1299e-05\n",
            "Epoch 9/1000\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 9.7973e-05 - val_loss: 8.6725e-05\n",
            "Epoch 10/1000\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 9.3265e-05 - val_loss: 8.4091e-05\n",
            "Epoch 11/1000\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 9.1079e-05 - val_loss: 8.8282e-05\n",
            "Epoch 12/1000\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 9.0980e-05 - val_loss: 1.0963e-04\n",
            "Epoch 13/1000\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 9.8202e-05 - val_loss: 7.8039e-05\n",
            "Epoch 14/1000\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 8.0463e-05 - val_loss: 7.6808e-05\n",
            "Epoch 15/1000\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 8.3453e-05 - val_loss: 7.8242e-05\n",
            "Epoch 16/1000\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 8.3501e-05 - val_loss: 7.4326e-05\n",
            "Epoch 17/1000\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 7.8345e-05 - val_loss: 7.5173e-05\n",
            "Epoch 18/1000\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 7.6945e-05 - val_loss: 7.5370e-05\n",
            "Epoch 19/1000\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 7.7494e-05 - val_loss: 7.7281e-05\n",
            "Epoch 20/1000\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 7.9934e-05 - val_loss: 7.5580e-05\n",
            "Epoch 21/1000\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 8.3857e-05 - val_loss: 7.6165e-05\n",
            "Epoch 22/1000\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 7.4580e-05 - val_loss: 7.1579e-05\n",
            "Epoch 23/1000\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 7.3402e-05 - val_loss: 7.3217e-05\n",
            "Epoch 24/1000\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 7.4638e-05 - val_loss: 7.5372e-05\n",
            "Epoch 25/1000\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 7.3569e-05 - val_loss: 7.7946e-05\n",
            "Epoch 26/1000\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 8.1789e-05 - val_loss: 8.9364e-05\n",
            "Epoch 27/1000\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 8.2352e-05 - val_loss: 8.2147e-05\n",
            "Epoch 28/1000\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 7.3954e-05 - val_loss: 7.9347e-05\n",
            "Epoch 29/1000\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 8.0616e-05 - val_loss: 7.8120e-05\n",
            "Epoch 30/1000\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 7.1858e-05 - val_loss: 6.8550e-05\n",
            "Epoch 31/1000\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 7.3100e-05 - val_loss: 7.8841e-05\n",
            "Epoch 32/1000\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 7.0743e-05 - val_loss: 6.8649e-05\n",
            "Epoch 33/1000\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 6.9595e-05 - val_loss: 7.1153e-05\n",
            "Epoch 34/1000\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 7.3430e-05 - val_loss: 8.2679e-05\n",
            "Epoch 35/1000\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 7.2658e-05 - val_loss: 7.0623e-05\n",
            "Epoch 36/1000\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 7.3347e-05 - val_loss: 7.0752e-05\n",
            "Epoch 37/1000\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 7.6429e-05 - val_loss: 7.5191e-05\n",
            "Epoch 38/1000\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 7.5672e-05 - val_loss: 8.7548e-05\n",
            "Epoch 39/1000\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 7.6274e-05 - val_loss: 7.6269e-05\n",
            "Epoch 40/1000\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 7.0213e-05 - val_loss: 7.5082e-05\n",
            "Epoch 41/1000\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 7.0244e-05 - val_loss: 7.8134e-05\n",
            "Epoch 42/1000\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 7.5125e-05 - val_loss: 1.0190e-04\n",
            "Epoch 43/1000\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 7.7276e-05 - val_loss: 8.2095e-05\n",
            "Epoch 44/1000\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 7.5141e-05 - val_loss: 8.2105e-05\n",
            "Epoch 45/1000\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 7.9132e-05 - val_loss: 6.7593e-05\n",
            "Epoch 46/1000\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 7.7972e-05 - val_loss: 6.7678e-05\n",
            "Epoch 47/1000\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 7.2063e-05 - val_loss: 7.1328e-05\n",
            "Epoch 48/1000\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 7.2278e-05 - val_loss: 7.8426e-05\n",
            "Epoch 49/1000\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 7.5909e-05 - val_loss: 6.6294e-05\n",
            "Epoch 50/1000\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 7.4403e-05 - val_loss: 8.1831e-05\n",
            "Epoch 00050: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f722d0353d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4xsL8u4SHKF",
        "outputId": "349ba84e-221b-45dd-9d81-28f0a4317de6"
      },
      "source": [
        "from math import sqrt\n",
        "from matplotlib import pyplot\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "\n",
        "\"\"\"\n",
        "pred_many = model.predict(X_val)\n",
        "rmse = sqrt(mean_squared_error(Y_val, pred_many))\n",
        "fig = pyplot.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "ax.plot(Y_val, label=\"Real\")\n",
        "ax.legend(loc='upper left')\n",
        "pyplot.plot(pred_many, label=\"Prediction\")\n",
        "pyplot.legend(loc='upper left')\n",
        "pyplot.savefig(imgPath)\n",
        "pyplot.clf()\n",
        "\"\"\"\n",
        "pred = model.predict(X_val)\n",
        "pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[-0.29861587],\n",
              "        [-0.29575658],\n",
              "        [-0.29669905],\n",
              "        [-0.2966503 ],\n",
              "        [-0.2959519 ]],\n",
              "\n",
              "       [[-0.06397185],\n",
              "        [-0.06455555],\n",
              "        [-0.06446442],\n",
              "        [-0.06443556],\n",
              "        [-0.06440888]],\n",
              "\n",
              "       [[-0.04232759],\n",
              "        [-0.04122655],\n",
              "        [-0.04029436],\n",
              "        [-0.03946568],\n",
              "        [-0.03870175]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[-0.01302751],\n",
              "        [-0.01178204],\n",
              "        [-0.01201375],\n",
              "        [-0.01241651],\n",
              "        [-0.01276767]],\n",
              "\n",
              "       [[-0.23128599],\n",
              "        [-0.23170087],\n",
              "        [-0.23077396],\n",
              "        [-0.23003304],\n",
              "        [-0.22925347]],\n",
              "\n",
              "       [[-0.07692419],\n",
              "        [-0.07753175],\n",
              "        [-0.07773903],\n",
              "        [-0.07807811],\n",
              "        [-0.07831961]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8Et-FEho4SU",
        "outputId": "5605dabb-0d0f-4725-fabc-4b55f3de0ffc"
      },
      "source": [
        "Y_val"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[-0.30032349],\n",
              "        [-0.30039908],\n",
              "        [-0.30002092],\n",
              "        [-0.30009651],\n",
              "        [-0.29790265]],\n",
              "\n",
              "       [[-0.06545521],\n",
              "        [-0.06419736],\n",
              "        [-0.05992023],\n",
              "        [-0.06000415],\n",
              "        [-0.06676909]],\n",
              "\n",
              "       [[-0.0438063 ],\n",
              "        [-0.0442977 ],\n",
              "        [-0.04406844],\n",
              "        [-0.04030028],\n",
              "        [-0.03928453]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[-0.01402029],\n",
              "        [-0.01716596],\n",
              "        [-0.02595749],\n",
              "        [-0.01725236],\n",
              "        [-0.01302905]],\n",
              "\n",
              "       [[-0.23173047],\n",
              "        [-0.23111652],\n",
              "        [-0.22960197],\n",
              "        [-0.23025693],\n",
              "        [-0.23062529]],\n",
              "\n",
              "       [[-0.08532259],\n",
              "        [-0.08270411],\n",
              "        [-0.0892644 ],\n",
              "        [-0.08687113],\n",
              "        [-0.0883352 ]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvIcgQAfpsi_"
      },
      "source": [
        "from numpy import ndarray\n",
        "Y_val = Y_val.flatten()\n",
        "pred = pred.flatten()\n",
        "rmse = sqrt(mean_squared_error(Y_val, pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuFVsxz5I6GN",
        "outputId": "b110fffe-cc85-4f8a-e7f2-21a23e8b262c"
      },
      "source": [
        "rmse"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.009046073094185793"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDoS9_Ag6Kp9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbfdmagWdwCp"
      },
      "source": [
        "from keras import regularizers\n",
        "def buildManyToManyModel(shape):\n",
        "  model = Sequential() \n",
        "  model.add(LSTM(32, input_shape=(shape[1], shape[2]), \n",
        "                    kernel_regularizer=regularizers.l2(0.01), \n",
        "                    recurrent_regularizer=regularizers.l2(0.01), \n",
        "                    bias_regularizer=regularizers.l2(0.01)))\n",
        "  model.add(RepeatVector(5)) \n",
        "  model.add(Dense(32,\n",
        "                    kernel_regularizer=regularizers.l2(0.01), \n",
        "                    bias_regularizer=regularizers.l2(0.01)))\n",
        "  model.add(Dropout(0.02))\n",
        "  model.add(TimeDistributed(Dense(1)))  \n",
        "  model.compile(loss=\"mse\", optimizer=\"adam\")\n",
        "  model.summary()\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6ndae6TeJg7",
        "outputId": "19c2d9be-6f7e-4d56-9cce-361db95ec05f"
      },
      "source": [
        "model = buildManyToManyModel(X_train.shape)\n",
        "callback = EarlyStopping(monitor=\"loss\", patience=10, verbose=1, mode=\"auto\")\n",
        "model.fit(X_train, Y_train, epochs=1000, batch_size=128, validation_data=(X_val, Y_val), callbacks=[callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_2 (LSTM)                (None, 32)                5504      \n",
            "_________________________________________________________________\n",
            "repeat_vector_2 (RepeatVecto (None, 5, 32)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 5, 32)             1056      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 5, 32)             0         \n",
            "_________________________________________________________________\n",
            "time_distributed (TimeDistri (None, 5, 1)              33        \n",
            "=================================================================\n",
            "Total params: 6,593\n",
            "Trainable params: 6,593\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/1000\n",
            "45/45 [==============================] - 31s 21ms/step - loss: 1.0773 - val_loss: 0.7732\n",
            "Epoch 2/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.7052 - val_loss: 0.5354\n",
            "Epoch 3/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.4953 - val_loss: 0.3939\n",
            "Epoch 4/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.3693 - val_loss: 0.3060\n",
            "Epoch 5/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.2902 - val_loss: 0.2486\n",
            "Epoch 6/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.2379 - val_loss: 0.2089\n",
            "Epoch 7/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.2012 - val_loss: 0.1797\n",
            "Epoch 8/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.1738 - val_loss: 0.1570\n",
            "Epoch 9/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.1523 - val_loss: 0.1384\n",
            "Epoch 10/1000\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.1344 - val_loss: 0.1226\n",
            "Epoch 11/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.1192 - val_loss: 0.1089\n",
            "Epoch 12/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.1058 - val_loss: 0.0967\n",
            "Epoch 13/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0940 - val_loss: 0.0858\n",
            "Epoch 14/1000\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0834 - val_loss: 0.0761\n",
            "Epoch 15/1000\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0738 - val_loss: 0.0673\n",
            "Epoch 16/1000\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0653 - val_loss: 0.0594\n",
            "Epoch 17/1000\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0576 - val_loss: 0.0523\n",
            "Epoch 18/1000\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 0.0507 - val_loss: 0.0460\n",
            "Epoch 19/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0447 - val_loss: 0.0404\n",
            "Epoch 20/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0392 - val_loss: 0.0354\n",
            "Epoch 21/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0344 - val_loss: 0.0310\n",
            "Epoch 22/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0301 - val_loss: 0.0272\n",
            "Epoch 23/1000\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0264 - val_loss: 0.0238\n",
            "Epoch 24/1000\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0230 - val_loss: 0.0208\n",
            "Epoch 25/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0202 - val_loss: 0.0182\n",
            "Epoch 26/1000\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0177 - val_loss: 0.0160\n",
            "Epoch 27/1000\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0155 - val_loss: 0.0140\n",
            "Epoch 28/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0137 - val_loss: 0.0125\n",
            "Epoch 29/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0121 - val_loss: 0.0109\n",
            "Epoch 30/1000\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0107 - val_loss: 0.0098\n",
            "Epoch 31/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0095 - val_loss: 0.0087\n",
            "Epoch 32/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0086 - val_loss: 0.0079\n",
            "Epoch 33/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0077 - val_loss: 0.0072\n",
            "Epoch 34/1000\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0070 - val_loss: 0.0065\n",
            "Epoch 35/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0064 - val_loss: 0.0060\n",
            "Epoch 36/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0059 - val_loss: 0.0055\n",
            "Epoch 37/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0055 - val_loss: 0.0052\n",
            "Epoch 38/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0052 - val_loss: 0.0049\n",
            "Epoch 39/1000\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0049 - val_loss: 0.0046\n",
            "Epoch 40/1000\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0046 - val_loss: 0.0044\n",
            "Epoch 41/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0044 - val_loss: 0.0042\n",
            "Epoch 42/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0042 - val_loss: 0.0041\n",
            "Epoch 43/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0041 - val_loss: 0.0039\n",
            "Epoch 44/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0040 - val_loss: 0.0038\n",
            "Epoch 45/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0039 - val_loss: 0.0038\n",
            "Epoch 46/1000\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0038 - val_loss: 0.0037\n",
            "Epoch 47/1000\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0037 - val_loss: 0.0036\n",
            "Epoch 48/1000\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0036 - val_loss: 0.0035\n",
            "Epoch 49/1000\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0036 - val_loss: 0.0035\n",
            "Epoch 50/1000\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0035 - val_loss: 0.0034\n",
            "Epoch 51/1000\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0035 - val_loss: 0.0034\n",
            "Epoch 52/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0034 - val_loss: 0.0033\n",
            "Epoch 53/1000\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0034 - val_loss: 0.0033\n",
            "Epoch 54/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0033 - val_loss: 0.0032\n",
            "Epoch 55/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0033 - val_loss: 0.0032\n",
            "Epoch 56/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0033 - val_loss: 0.0032\n",
            "Epoch 57/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0032 - val_loss: 0.0031\n",
            "Epoch 58/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0032 - val_loss: 0.0031\n",
            "Epoch 59/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0032 - val_loss: 0.0031\n",
            "Epoch 60/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0031 - val_loss: 0.0030\n",
            "Epoch 61/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0031 - val_loss: 0.0030\n",
            "Epoch 62/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0030 - val_loss: 0.0030\n",
            "Epoch 63/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0030 - val_loss: 0.0029\n",
            "Epoch 64/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0030 - val_loss: 0.0029\n",
            "Epoch 65/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0029 - val_loss: 0.0029\n",
            "Epoch 66/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0030 - val_loss: 0.0028\n",
            "Epoch 67/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 68/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0029 - val_loss: 0.0029\n",
            "Epoch 69/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0029 - val_loss: 0.0028\n",
            "Epoch 70/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 71/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 72/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0028 - val_loss: 0.0027\n",
            "Epoch 73/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0027 - val_loss: 0.0027\n",
            "Epoch 74/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0027 - val_loss: 0.0026\n",
            "Epoch 75/1000\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 0.0027 - val_loss: 0.0026\n",
            "Epoch 76/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0027 - val_loss: 0.0026\n",
            "Epoch 77/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0027 - val_loss: 0.0026\n",
            "Epoch 78/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0027 - val_loss: 0.0025\n",
            "Epoch 79/1000\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0026 - val_loss: 0.0025\n",
            "Epoch 80/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0026 - val_loss: 0.0026\n",
            "Epoch 81/1000\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0026 - val_loss: 0.0025\n",
            "Epoch 82/1000\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0026 - val_loss: 0.0025\n",
            "Epoch 83/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0025 - val_loss: 0.0024\n",
            "Epoch 84/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0025 - val_loss: 0.0024\n",
            "Epoch 85/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0025 - val_loss: 0.0024\n",
            "Epoch 86/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0025 - val_loss: 0.0024\n",
            "Epoch 87/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0025 - val_loss: 0.0024\n",
            "Epoch 88/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0024 - val_loss: 0.0023\n",
            "Epoch 89/1000\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0024 - val_loss: 0.0024\n",
            "Epoch 90/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0024 - val_loss: 0.0023\n",
            "Epoch 91/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0024 - val_loss: 0.0023\n",
            "Epoch 92/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0024 - val_loss: 0.0023\n",
            "Epoch 93/1000\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0023 - val_loss: 0.0023\n",
            "Epoch 94/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0023 - val_loss: 0.0023\n",
            "Epoch 95/1000\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0023 - val_loss: 0.0023\n",
            "Epoch 96/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0023 - val_loss: 0.0022\n",
            "Epoch 97/1000\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0023 - val_loss: 0.0022\n",
            "Epoch 98/1000\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0023 - val_loss: 0.0022\n",
            "Epoch 99/1000\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0023 - val_loss: 0.0022\n",
            "Epoch 100/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0022 - val_loss: 0.0022\n",
            "Epoch 101/1000\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0022 - val_loss: 0.0022\n",
            "Epoch 102/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0022 - val_loss: 0.0021\n",
            "Epoch 103/1000\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0022 - val_loss: 0.0022\n",
            "Epoch 104/1000\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0022 - val_loss: 0.0021\n",
            "Epoch 105/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0022 - val_loss: 0.0021\n",
            "Epoch 106/1000\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0021 - val_loss: 0.0021\n",
            "Epoch 107/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0021 - val_loss: 0.0021\n",
            "Epoch 108/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0021 - val_loss: 0.0020\n",
            "Epoch 109/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0021 - val_loss: 0.0020\n",
            "Epoch 110/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0021 - val_loss: 0.0021\n",
            "Epoch 111/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0021 - val_loss: 0.0020\n",
            "Epoch 112/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0021 - val_loss: 0.0020\n",
            "Epoch 113/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0021 - val_loss: 0.0020\n",
            "Epoch 114/1000\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 0.0020\n",
            "Epoch 115/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0020 - val_loss: 0.0020\n",
            "Epoch 116/1000\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 0.0019\n",
            "Epoch 117/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0020 - val_loss: 0.0020\n",
            "Epoch 118/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0020 - val_loss: 0.0019\n",
            "Epoch 119/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0020 - val_loss: 0.0019\n",
            "Epoch 120/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0020 - val_loss: 0.0019\n",
            "Epoch 121/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0020 - val_loss: 0.0019\n",
            "Epoch 122/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 0.0019\n",
            "Epoch 123/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 0.0019\n",
            "Epoch 124/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 0.0019\n",
            "Epoch 125/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 0.0019\n",
            "Epoch 126/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 0.0018\n",
            "Epoch 127/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 0.0018\n",
            "Epoch 128/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 0.0018\n",
            "Epoch 129/1000\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0019 - val_loss: 0.0018\n",
            "Epoch 130/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 0.0018\n",
            "Epoch 131/1000\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 0.0018\n",
            "Epoch 132/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 0.0018\n",
            "Epoch 133/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 0.0018\n",
            "Epoch 134/1000\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0019 - val_loss: 0.0017\n",
            "Epoch 135/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 136/1000\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 137/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 138/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 139/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 0.0018\n",
            "Epoch 140/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 141/1000\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 0.0017 - val_loss: 0.0017\n",
            "Epoch 142/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 0.0017\n",
            "Epoch 143/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 0.0018\n",
            "Epoch 144/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 145/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 0.0016\n",
            "Epoch 146/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 0.0016\n",
            "Epoch 147/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 0.0016\n",
            "Epoch 148/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 0.0016\n",
            "Epoch 149/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 0.0016\n",
            "Epoch 150/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 0.0016\n",
            "Epoch 151/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 0.0016\n",
            "Epoch 152/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 0.0016\n",
            "Epoch 153/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 0.0016\n",
            "Epoch 154/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 0.0016\n",
            "Epoch 155/1000\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 0.0017 - val_loss: 0.0016\n",
            "Epoch 156/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 0.0016\n",
            "Epoch 157/1000\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 0.0015\n",
            "Epoch 158/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 0.0016\n",
            "Epoch 159/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 0.0015\n",
            "Epoch 160/1000\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 0.0016 - val_loss: 0.0015\n",
            "Epoch 161/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 0.0015\n",
            "Epoch 162/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 0.0015\n",
            "Epoch 163/1000\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 0.0016 - val_loss: 0.0015\n",
            "Epoch 164/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 0.0015\n",
            "Epoch 165/1000\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 0.0015 - val_loss: 0.0015\n",
            "Epoch 166/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 0.0015\n",
            "Epoch 167/1000\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 0.0015 - val_loss: 0.0016\n",
            "Epoch 168/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 0.0015\n",
            "Epoch 169/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 0.0014\n",
            "Epoch 170/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 0.0015\n",
            "Epoch 171/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 0.0014\n",
            "Epoch 172/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 0.0015\n",
            "Epoch 173/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 0.0015\n",
            "Epoch 174/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 0.0014\n",
            "Epoch 175/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 0.0014\n",
            "Epoch 176/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 0.0014\n",
            "Epoch 177/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 0.0014\n",
            "Epoch 178/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 0.0014\n",
            "Epoch 179/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 0.0014\n",
            "Epoch 180/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 0.0014\n",
            "Epoch 181/1000\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 0.0014\n",
            "Epoch 182/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 0.0014\n",
            "Epoch 183/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 0.0014\n",
            "Epoch 184/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 0.0014\n",
            "Epoch 185/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 0.0014\n",
            "Epoch 186/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 0.0014\n",
            "Epoch 187/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 0.0013\n",
            "Epoch 188/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 0.0014\n",
            "Epoch 189/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 0.0013\n",
            "Epoch 190/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 0.0013\n",
            "Epoch 191/1000\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 0.0014 - val_loss: 0.0013\n",
            "Epoch 192/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 0.0014\n",
            "Epoch 193/1000\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 0.0014 - val_loss: 0.0013\n",
            "Epoch 194/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 0.0013\n",
            "Epoch 195/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 0.0013\n",
            "Epoch 196/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 0.0013\n",
            "Epoch 197/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 0.0013\n",
            "Epoch 198/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 0.0013\n",
            "Epoch 199/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 0.0013\n",
            "Epoch 200/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 0.0013\n",
            "Epoch 201/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 0.0013\n",
            "Epoch 202/1000\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 0.0012\n",
            "Epoch 203/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 0.0013\n",
            "Epoch 204/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 0.0012\n",
            "Epoch 205/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 0.0012\n",
            "Epoch 206/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 0.0013\n",
            "Epoch 207/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 0.0012\n",
            "Epoch 208/1000\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 0.0012\n",
            "Epoch 209/1000\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 0.0012\n",
            "Epoch 210/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 0.0012\n",
            "Epoch 211/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 0.0012\n",
            "Epoch 212/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 0.0013\n",
            "Epoch 213/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 0.0012\n",
            "Epoch 214/1000\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 0.0012\n",
            "Epoch 215/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.0012\n",
            "Epoch 216/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 0.0012\n",
            "Epoch 217/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.0012\n",
            "Epoch 218/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.0013\n",
            "Epoch 219/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 0.0013\n",
            "Epoch 220/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 0.0012\n",
            "Epoch 221/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.0012\n",
            "Epoch 222/1000\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 0.0012 - val_loss: 0.0012\n",
            "Epoch 223/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.0012\n",
            "Epoch 224/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.0012\n",
            "Epoch 225/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.0012\n",
            "Epoch 226/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.0012\n",
            "Epoch 227/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.0011\n",
            "Epoch 228/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.0012\n",
            "Epoch 229/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.0012\n",
            "Epoch 230/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.0011\n",
            "Epoch 231/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.0013\n",
            "Epoch 232/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.0011\n",
            "Epoch 233/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.0011\n",
            "Epoch 234/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.0011\n",
            "Epoch 235/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.0011\n",
            "Epoch 236/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.0011\n",
            "Epoch 237/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.0012\n",
            "Epoch 238/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.0011\n",
            "Epoch 239/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.0011\n",
            "Epoch 240/1000\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 0.0011\n",
            "Epoch 241/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.0011\n",
            "Epoch 242/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.0012\n",
            "Epoch 243/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.0011\n",
            "Epoch 244/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.0011\n",
            "Epoch 245/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.0011\n",
            "Epoch 246/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.0012\n",
            "Epoch 247/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.0011\n",
            "Epoch 248/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.0011\n",
            "Epoch 249/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.0011\n",
            "Epoch 250/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.0010\n",
            "Epoch 251/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.0011\n",
            "Epoch 252/1000\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 0.0011\n",
            "Epoch 253/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.0010\n",
            "Epoch 254/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.0011\n",
            "Epoch 255/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.0011\n",
            "Epoch 256/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.0011\n",
            "Epoch 257/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.0010\n",
            "Epoch 258/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.0011\n",
            "Epoch 259/1000\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 0.0011\n",
            "Epoch 260/1000\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 0.0010\n",
            "Epoch 261/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.0010\n",
            "Epoch 262/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.0011\n",
            "Epoch 263/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.0011\n",
            "Epoch 264/1000\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0010\n",
            "Epoch 265/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.0010\n",
            "Epoch 266/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.0011\n",
            "Epoch 267/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 9.9854e-04\n",
            "Epoch 268/1000\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 9.8898e-04\n",
            "Epoch 269/1000\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 0.0010 - val_loss: 9.8694e-04\n",
            "Epoch 270/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 9.7870e-04\n",
            "Epoch 271/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 9.8470e-04\n",
            "Epoch 272/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 9.7688e-04\n",
            "Epoch 273/1000\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 0.0010 - val_loss: 0.0010\n",
            "Epoch 274/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 9.8518e-04\n",
            "Epoch 275/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 0.0010\n",
            "Epoch 276/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 9.8547e-04\n",
            "Epoch 277/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 9.7297e-04\n",
            "Epoch 278/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 0.0010\n",
            "Epoch 279/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 9.7806e-04\n",
            "Epoch 280/1000\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 0.0010 - val_loss: 9.6727e-04\n",
            "Epoch 281/1000\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 0.0010 - val_loss: 0.0010\n",
            "Epoch 282/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 0.0011\n",
            "Epoch 283/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.0011\n",
            "Epoch 284/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 0.0010\n",
            "Epoch 285/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 9.6967e-04\n",
            "Epoch 286/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 9.4053e-04\n",
            "Epoch 287/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 9.7844e-04\n",
            "Epoch 288/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 9.9618e-04 - val_loss: 9.2991e-04\n",
            "Epoch 289/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 0.0011\n",
            "Epoch 290/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 9.8686e-04\n",
            "Epoch 291/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 9.4607e-04\n",
            "Epoch 292/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 9.5547e-04\n",
            "Epoch 293/1000\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 9.9309e-04 - val_loss: 9.2902e-04\n",
            "Epoch 294/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 9.8828e-04 - val_loss: 9.2237e-04\n",
            "Epoch 295/1000\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 9.9251e-04 - val_loss: 9.6042e-04\n",
            "Epoch 296/1000\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 0.0010 - val_loss: 9.4835e-04\n",
            "Epoch 297/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 9.7759e-04 - val_loss: 9.3845e-04\n",
            "Epoch 298/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 9.4016e-04\n",
            "Epoch 299/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 9.8381e-04 - val_loss: 9.4397e-04\n",
            "Epoch 300/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 9.6327e-04 - val_loss: 9.9677e-04\n",
            "Epoch 301/1000\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 0.0010 - val_loss: 8.9873e-04\n",
            "Epoch 302/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 9.7234e-04 - val_loss: 8.9689e-04\n",
            "Epoch 303/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 9.7430e-04 - val_loss: 8.9875e-04\n",
            "Epoch 304/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 9.5566e-04 - val_loss: 9.0370e-04\n",
            "Epoch 305/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 9.6654e-04 - val_loss: 0.0010\n",
            "Epoch 306/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 9.6969e-04 - val_loss: 8.9507e-04\n",
            "Epoch 307/1000\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 9.5199e-04 - val_loss: 9.1294e-04\n",
            "Epoch 308/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 9.5828e-04 - val_loss: 9.4102e-04\n",
            "Epoch 309/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 9.7568e-04 - val_loss: 9.1325e-04\n",
            "Epoch 310/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 9.7511e-04 - val_loss: 9.1768e-04\n",
            "Epoch 311/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 9.6333e-04 - val_loss: 8.8861e-04\n",
            "Epoch 312/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 9.3456e-04 - val_loss: 8.7581e-04\n",
            "Epoch 313/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 9.3490e-04 - val_loss: 8.7152e-04\n",
            "Epoch 314/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 9.3345e-04 - val_loss: 8.9384e-04\n",
            "Epoch 315/1000\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 9.4536e-04 - val_loss: 9.8674e-04\n",
            "Epoch 316/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 9.8578e-04 - val_loss: 9.6967e-04\n",
            "Epoch 317/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 9.9285e-04 - val_loss: 8.9003e-04\n",
            "Epoch 318/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 9.2881e-04 - val_loss: 8.9201e-04\n",
            "Epoch 319/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 9.5580e-04 - val_loss: 8.9457e-04\n",
            "Epoch 320/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 9.1841e-04 - val_loss: 9.0578e-04\n",
            "Epoch 321/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 9.6863e-04 - val_loss: 8.6958e-04\n",
            "Epoch 322/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 9.1712e-04 - val_loss: 8.8467e-04\n",
            "Epoch 323/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 9.2117e-04 - val_loss: 9.0052e-04\n",
            "Epoch 324/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 9.4394e-04 - val_loss: 8.5260e-04\n",
            "Epoch 325/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 9.6766e-04 - val_loss: 9.1622e-04\n",
            "Epoch 326/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 9.8404e-04 - val_loss: 8.9189e-04\n",
            "Epoch 327/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 9.1940e-04 - val_loss: 8.7438e-04\n",
            "Epoch 328/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 9.2453e-04 - val_loss: 8.5770e-04\n",
            "Epoch 329/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 9.0587e-04 - val_loss: 8.4206e-04\n",
            "Epoch 330/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 9.0421e-04 - val_loss: 8.7324e-04\n",
            "Epoch 331/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 9.0360e-04 - val_loss: 8.9566e-04\n",
            "Epoch 332/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 9.2641e-04 - val_loss: 8.5548e-04\n",
            "Epoch 333/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 9.6580e-04 - val_loss: 8.7297e-04\n",
            "Epoch 334/1000\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 9.5039e-04 - val_loss: 8.6761e-04\n",
            "Epoch 335/1000\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 8.8872e-04 - val_loss: 8.8004e-04\n",
            "Epoch 336/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 9.0793e-04 - val_loss: 9.3767e-04\n",
            "Epoch 337/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 9.1881e-04 - val_loss: 8.8069e-04\n",
            "Epoch 338/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 9.0456e-04 - val_loss: 8.3436e-04\n",
            "Epoch 339/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 9.6021e-04 - val_loss: 8.4913e-04\n",
            "Epoch 340/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 9.1304e-04 - val_loss: 8.2522e-04\n",
            "Epoch 341/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 9.0611e-04 - val_loss: 9.1769e-04\n",
            "Epoch 342/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 9.2316e-04 - val_loss: 9.4036e-04\n",
            "Epoch 343/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 9.1243e-04 - val_loss: 8.4229e-04\n",
            "Epoch 344/1000\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 9.0507e-04 - val_loss: 8.4818e-04\n",
            "Epoch 345/1000\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 8.9593e-04 - val_loss: 8.2193e-04\n",
            "Epoch 00345: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f903025c410>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCHMBhukeNu-",
        "outputId": "d387116a-8d90-40fa-fd86-e64721f65a62"
      },
      "source": [
        "from math import sqrt\n",
        "from matplotlib import pyplot\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "\n",
        "\"\"\"\n",
        "pred_many = model.predict(X_val)\n",
        "rmse = sqrt(mean_squared_error(Y_val, pred_many))\n",
        "fig = pyplot.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "ax.plot(Y_val, label=\"Real\")\n",
        "ax.legend(loc='upper left')\n",
        "pyplot.plot(pred_many, label=\"Prediction\")\n",
        "pyplot.legend(loc='upper left')\n",
        "pyplot.savefig(imgPath)\n",
        "pyplot.clf()\n",
        "\"\"\"\n",
        "pred = model.predict(X_val)\n",
        "pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[-0.3092832 ],\n",
              "        [-0.3092832 ],\n",
              "        [-0.3092832 ],\n",
              "        [-0.3092832 ],\n",
              "        [-0.3092832 ]],\n",
              "\n",
              "       [[-0.05640321],\n",
              "        [-0.05640321],\n",
              "        [-0.05640321],\n",
              "        [-0.05640321],\n",
              "        [-0.05640321]],\n",
              "\n",
              "       [[-0.04012572],\n",
              "        [-0.04012572],\n",
              "        [-0.04012572],\n",
              "        [-0.04012572],\n",
              "        [-0.04012572]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[-0.00244225],\n",
              "        [-0.00244225],\n",
              "        [-0.00244225],\n",
              "        [-0.00244225],\n",
              "        [-0.00244225]],\n",
              "\n",
              "       [[-0.23745273],\n",
              "        [-0.23745273],\n",
              "        [-0.23745273],\n",
              "        [-0.23745273],\n",
              "        [-0.23745273]],\n",
              "\n",
              "       [[-0.07253215],\n",
              "        [-0.07253215],\n",
              "        [-0.07253215],\n",
              "        [-0.07253215],\n",
              "        [-0.07253215]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jEtYgT6qfhLY",
        "outputId": "7031363a-50fd-4ad3-ba3c-f42e9877009c"
      },
      "source": [
        "from numpy import ndarray\n",
        "Y_val = Y_val.flatten()\n",
        "pred = pred.flatten()\n",
        "rmse = sqrt(mean_squared_error(Y_val, pred))\n",
        "print(rmse)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.012478853479115287\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVh74v1jflyv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}